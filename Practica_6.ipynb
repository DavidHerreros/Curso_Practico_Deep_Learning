{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PRÁCTICA 6: REDES GENERATIVAS ANTAGÓNICAS (GAN)\n",
    "\n",
    "En esta práctica vamos a definir ina red generativa antagónica (__GAN__), siendo esta arquitectura muy popular graicas a su capacidad mejorada de generación de datos en comparación a otras arquitecturas más clásicas como los __Autoencoder__.\n",
    "\n",
    "Este tipo de redes son además un muy buen ejemplo para aprender a trabajar con diferentes optimizadores y pasos de backpropagation, lo que nos permite tener un mayor control de como se actualizan y comportan diferentes partes de nuestra red.\n",
    "\n",
    "Vamos a comenzar importando las librerías que necesitaremos durante la práctica:"
   ],
   "id": "ad6d51a7e12dc374"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:24:05.388520Z",
     "start_time": "2025-05-08T12:24:04.932666Z"
    }
   },
   "cell_type": "code",
   "source": "!jupyter nbextension enable --py widgetsnbextension",
   "id": "de45d31fd8473cd0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001B[32mOK\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:24:07.609403Z",
     "start_time": "2025-05-08T12:24:05.511305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "# Librerías de PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Torch vision para descargar y preprocesar el conjunto de datos que usaremos para entrenar la red\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "# Herramientas adicionales para la visualización de los datos y resultados\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "id": "6d24578065445be0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Como hemos hecho en otras prácticas, vamos a continuar definiendo una seria de variables para configurar parte de los hiperparámetros de la red:",
   "id": "25deaaefe92b5bcd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:24:07.620090Z",
     "start_time": "2025-05-08T12:24:07.617312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NUM_EPOCHS = 50\n",
    "NOISE_DIMENSION = 50\n",
    "BATCH_SIZE = 128\n",
    "TRAIN_ON_GPU = True\n",
    "UNIQUE_RUN_ID = str(uuid.uuid4())\n",
    "PRINT_STATS_AFTER_BATCH = 50\n",
    "OPTIMIZER_LR = 0.0002\n",
    "OPTIMIZER_BETAS = (0.5, 0.999)\n",
    "GENERATOR_OUTPUT_IMAGE_SHAPE = 28 * 28 * 1"
   ],
   "id": "4e1372c48b498f8c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "También vamos a aprovehcar a configurar __PyTorch__ con el objetivo de mejorar la velocidad de ejecución de nuestra red:",
   "id": "5c8eedc9b4938290"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:24:07.671852Z",
     "start_time": "2025-05-08T12:24:07.669054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.autograd.set_detect_anomaly(False)\n",
    "torch.autograd.profiler.profile(False)\n",
    "torch.autograd.profiler.emit_nvtx(False)\n",
    "torch.backends.cudnn.benchmark = True"
   ],
   "id": "9a5b7d723fdb32aa",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Durante esta práctica usaremos de nuevo el conjunto de datos `FashionMNIST` para entrenar la red. Comenzaremos por descargar y generar el `DataLoader` para poder enviar datos a la red de manera eficiente:",
   "id": "a95e95f1705000db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:24:08.023079Z",
     "start_time": "2025-05-08T12:24:07.718613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = datasets.FashionMNIST(\"./MNIST_DATA\", train=True, download=True,transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True, num_workers=4)"
   ],
   "id": "555376aad9449e7f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "También podemos aprovechar para visualizar los datos como hemos hecho en prácticas anteriores:",
   "id": "4074258da41a9d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:24:08.237342Z",
     "start_time": "2025-05-08T12:24:08.033538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Inspección de los datos de entrenamiento: \")\n",
    "for _, data in enumerate(train_loader):\n",
    "    print(\"Tamaño del lote: \", data[0].shape)\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(10, 4))\n",
    "\n",
    "    for i in range(4):\n",
    "        ax[i].imshow(data[0][i].squeeze(), cmap=\"gray\")\n",
    "        ax[i].axis(\"off\")\n",
    "    plt.show()\n",
    "    # Hacemos break para no recorrer todo el loader\n",
    "    break"
   ],
   "id": "9df1d96adb4d25ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspección de los datos de entrenamiento: \n",
      "Tamaño del lote:  torch.Size([64, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 4 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8F2BDwhBH4DdYhx5e7u04A.jpeg\">\n",
    "\n",
    "Las redes __GAN__ están formadas por dos redes neuronales diferentes:\n",
    "- **Generador**: Tiene como objetivo aprender a generar datos a partir de una entrada \"fija\" (en nuestro caso, una imagen de ruido)\n",
    "- **Discriminador**: Esta red tiene como objetivo aprender a discriminar sin una imgen es real o falsa (es decir, generada por el **Generador**).\n",
    "\n",
    "El proceso de entrenamiento de este tipo de redes se puede comparar con el de un falsificador y un policía. El **Generador** actúa como el falsificador, mientras que la tarea de la policía es atraparlo. Cuando la policía detecta más imágenes falsificadas, el falsificador debe aprender a producir mejores resultados. Esto es exactamente lo que sucede: a medida que el **Discriminador** mejora su capacidad para discernir si una imagen es falsa o real, el **Generador** finalmente mejora su capacidad para generar imágenes falsas. En consecuencia, el **Generador** puede utilizarse de forma independiente para generar imágenes después de su entrenamiento.\n",
    "\n",
    "Vamos a comenzar definiendo nuestro **Generador**:"
   ],
   "id": "396cc2928ec0c109"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:24:08.264672Z",
     "start_time": "2025-05-08T12:24:08.261032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Generator(nn.Module):\n",
    "  def __init__(self,):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(NOISE_DIMENSION, 128),\n",
    "      nn.BatchNorm1d(128, 0.8),\n",
    "      nn.LeakyReLU(0.25),\n",
    "      nn.Linear(128, 256),\n",
    "      nn.BatchNorm1d(256, 0.8),\n",
    "      nn.LeakyReLU(0.25),\n",
    "      nn.Linear(256, 512),\n",
    "      nn.BatchNorm1d(512, 0.8),\n",
    "      nn.LeakyReLU(0.25),\n",
    "      nn.Linear(512, GENERATOR_OUTPUT_IMAGE_SHAPE),\n",
    "      nn.Tanh()\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.layers(x)"
   ],
   "id": "2b710b2bb44aa2d6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Y continuamos con la definición del **Discriminador**:",
   "id": "427baa814be90250"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:24:08.346469Z",
     "start_time": "2025-05-08T12:24:08.343049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Discriminator(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(GENERATOR_OUTPUT_IMAGE_SHAPE, 1024),\n",
    "      nn.LeakyReLU(0.25),\n",
    "      nn.Linear(1024, 512),\n",
    "      nn.LeakyReLU(0.25),\n",
    "      nn.Linear(512, 256),\n",
    "      nn.LeakyReLU(0.25),\n",
    "      nn.Linear(256, 1),\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.layers(x)"
   ],
   "id": "de9c47ec6f3aed82",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Antes de entranar nuestras dos redes, vamos a definir una serie de funciones que serán útiles durante el entrenamiento y la evaluación de los resultados de las dos redes:",
   "id": "1d81433df629fc08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:24:08.504230Z",
     "start_time": "2025-05-08T12:24:08.427846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_device():\n",
    "  return torch.device(\"cuda:0\" if torch.cuda.is_available() and TRAIN_ON_GPU else \"cpu\")\n",
    "\n",
    "def make_directory_for_run():\n",
    "  \"\"\" Vamos a guardar los resultados de cada ejecución en una carpeta diferente \"\"\"\n",
    "  print(f'Preparando la ejecución {UNIQUE_RUN_ID}')\n",
    "  if not os.path.exists('./runs'):\n",
    "    os.mkdir('./runs')\n",
    "  os.mkdir(f'./runs/{UNIQUE_RUN_ID}')\n",
    "\n",
    "def generate_noise(number_of_images=1, noise_dimension=NOISE_DIMENSION, device=None):\n",
    "  return torch.randn(number_of_images, noise_dimension, device=device)\n",
    "\n",
    "def generate_image(generator, epoch=0, batch=0, device=get_device()):\n",
    "  images = []\n",
    "  noise = generate_noise(BATCH_SIZE, device=device)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    images = generator(noise)\n",
    "\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  for i in range(16):\n",
    "    image = images[i]\n",
    "\n",
    "    image = image.cpu().numpy()\n",
    "    image = np.reshape(image, (28, 28))\n",
    "\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "  if not os.path.exists(f'./runs/{UNIQUE_RUN_ID}/images'):\n",
    "    os.mkdir(f'./runs/{UNIQUE_RUN_ID}/images')\n",
    "  plt.savefig(f'./runs/{UNIQUE_RUN_ID}/images/epoch{epoch}_batch{batch}.jpg')\n",
    "  plt.close()\n",
    "\n",
    "def save_models(generator, discriminator, epoch):\n",
    "  \"\"\" Save models at specific point in time. \"\"\"\n",
    "  torch.save(generator.state_dict(), f'./runs/{UNIQUE_RUN_ID}/generator_{epoch}.pth')\n",
    "  torch.save(discriminator.state_dict(), f'./runs/{UNIQUE_RUN_ID}/discriminator_{epoch}.pth')"
   ],
   "id": "e59b73abdbe36f86",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Continuamos con una seria de funciones de inicialización, encargadas de inicializar nuestras redes, funciones de péridida y los optimizadores que se usaran para actualizar los parámetros de cada red de manera independiente:",
   "id": "c9710a471f290dee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:24:08.578562Z",
     "start_time": "2025-05-08T12:24:08.574787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initialize_models(device=get_device()):\n",
    "  generator = Generator()\n",
    "  discriminator = Discriminator()\n",
    "  generator.to(device)\n",
    "  discriminator.to(device)\n",
    "  return generator, discriminator\n",
    "\n",
    "def initialize_optimizers(generator, discriminator):\n",
    "  generator_optimizer = torch.optim.AdamW(generator.parameters(), lr=OPTIMIZER_LR,betas=OPTIMIZER_BETAS)\n",
    "  discriminator_optimizer = torch.optim.AdamW(discriminator.parameters(), lr=OPTIMIZER_LR,betas=OPTIMIZER_BETAS)\n",
    "  return generator_optimizer, discriminator_optimizer"
   ],
   "id": "e5ba72588e5a8cb0",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Por último, vamos a definir una función adicional para anular nuestros gradientes.\n",
    "\n",
    "Esta función tiene un efecto similar a ``optimizer-zero_grad()`` pero es más eficiente. En la mayoría de casos, podemos usar esta nueva función para mejorar la velocidad de entrenamiento sin afectar a la precisión de los resultados obtenidos (aunque es importante mencionar que la estabilidad númerica de estas dos funciones es diferentes y se pueden producir pequeñas desviaciones numéricas en los parámetros de la red al usar una u otra)."
   ],
   "id": "b82d9192a018bd7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:24:08.661169Z",
     "start_time": "2025-05-08T12:24:08.656727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def efficient_zero_grad(model):\n",
    "\n",
    "  for param in model.parameters():\n",
    "    param.grad = None"
   ],
   "id": "7e97cf7b9a6ad5bb",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Por último definimos nuestro loop de entrenamiento:",
   "id": "9a481778cab5ec6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:24:08.738622Z",
     "start_time": "2025-05-08T12:24:08.727246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(generator, discriminator):\n",
    "    # Optimizadores\n",
    "    opt_generator, opt_discriminator = initialize_optimizers(generator, discriminator)\n",
    "\n",
    "    # Dataloader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=4)\n",
    "\n",
    "    # Función de pérdida\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    device = get_device()\n",
    "    make_directory_for_run()\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Barra de progreso\n",
    "        bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc=f\"Train epoch {epoch}\")\n",
    "\n",
    "        train_loss_disc = 0.0\n",
    "        train_loss_gen = 0.0\n",
    "\n",
    "        for i, (x, _) in enumerate(train_loader):\n",
    "            real_label, fake_label = 1.0, 0.0\n",
    "\n",
    "            real_images = x.to(device)\n",
    "            label = torch.full((BATCH_SIZE, 1), real_label, device=device)\n",
    "\n",
    "            # PASO 1: Entrenamiento del discriminador\n",
    "            efficient_zero_grad(discriminator)\n",
    "\n",
    "            # Imágenes reales\n",
    "            real_images = real_images.view(real_images.size(0), -1)\n",
    "            y = discriminator(real_images)\n",
    "            loss_disc_real = loss_fn(y, label)\n",
    "            loss_disc_real.backward()\n",
    "\n",
    "            # Imágenes falsas\n",
    "            noise = generate_noise(BATCH_SIZE, device=device)\n",
    "            generated_images = generator(noise)\n",
    "            label.fill_(fake_label)\n",
    "            y = discriminator(generated_images.detach())  # Como aquí no entrenamos el generador, tenemos que usar detach() para que PyTorch no tenga en cuenta su gradiente\n",
    "            loss_disc_fake = loss_fn(y, label)\n",
    "            loss_disc_fake.backward()\n",
    "\n",
    "            opt_discriminator.step()\n",
    "\n",
    "            ########################################\n",
    "\n",
    "            # PASO 2: Entrenamiento del generador\n",
    "            efficient_zero_grad(generator)\n",
    "            label.fill_(real_label)\n",
    "            y = discriminator(generated_images)  # Como aquí no entrenamos el generador, tenemos que usar detach() para que PyTorch no tenga en cuenta su gradiente\n",
    "            loss_gen = loss_fn(y, label)\n",
    "            loss_gen.backward()\n",
    "            opt_generator.step()\n",
    "\n",
    "            #####################################\n",
    "\n",
    "            # Pérdidas finales\n",
    "            loss_disc = loss_disc_real + loss_disc_fake\n",
    "\n",
    "            train_loss_disc += loss_disc.item()\n",
    "            train_loss_gen += loss_gen.item()\n",
    "\n",
    "            bar.set_postfix(\n",
    "            loss_disc=f\"{train_loss_disc/(i+1):.4f}\",\n",
    "            loss_gen=f\"{train_loss_gen/(i+1):.4f}\",\n",
    "            )\n",
    "            bar.update()\n",
    "\n",
    "        bar.close()\n",
    "\n",
    "        # Guardamos los modelos para cada epoch (checkpointing)\n",
    "        save_models(generator, discriminator, epoch)\n",
    "\n",
    "        # Guardamos las imágenes del generador\n",
    "        generate_image(generator, epoch=epoch, batch=i)\n",
    "\n",
    "        # Liberamos la memoria tras cada epoch\n",
    "        torch.cuda.empty_cache()"
   ],
   "id": "2d5ce4cc1ceae1e2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Por último, entrenamos nuestros modelos:",
   "id": "658e46a7dc1754b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:29:47.912204Z",
     "start_time": "2025-05-08T12:24:08.802767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generator, discriminator = initialize_models()\n",
    "train(generator, discriminator)"
   ],
   "id": "6785a41a3985d9bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando la ejecución d7441c09-da17-4cd0-9c08-c6975f1cd905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Imágenes generador en la primera epoch:\n",
    "\n",
    "<img src=\"./runs/d7441c09-da17-4cd0-9c08-c6975f1cd905/images/epoch0_batch467.jpg\" width=500 />\n",
    "\n",
    "Imágenes generador en la última epoch:\n",
    "\n",
    "<img src=\"./runs/d7441c09-da17-4cd0-9c08-c6975f1cd905/images/epoch49_batch467.jpg\" width=500 />"
   ],
   "id": "bb89bcd0e227fe9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
